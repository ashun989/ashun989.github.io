<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ashun989.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="论文：Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation 作者： Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, Rob Fergus 录用情况：Neurips&#39;2014 第一作者单位：Dept. of C">
<meta property="og:type" content="article">
<meta property="og:title" content="探索卷积网络的线性性质来进行推理时加速">
<meta property="og:url" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/index.html">
<meta property="og:site_name" content="Ashun&#39;s Blog">
<meta property="og:description" content="论文：Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation 作者： Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, Rob Fergus 录用情况：Neurips&#39;2014 第一作者单位：Dept. of C">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/image-20221017160950770.png">
<meta property="og:image" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/v2-3cee35b79d272dda86e2604c160934ee_720w.jpeg">
<meta property="og:image" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/image-20221017161636024.png">
<meta property="og:image" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/image-20221102223532182.png">
<meta property="article:published_time" content="2022-10-13T09:06:54.000Z">
<meta property="article:modified_time" content="2023-02-12T12:24:32.281Z">
<meta property="article:author" content="ashun">
<meta property="article:tag" content="模型压缩">
<meta property="article:tag" content="卷积分解">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/image-20221017160950770.png">


<link rel="canonical" href="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/","path":"2022/10/13/Linear-Structure-Within-Conv/","title":"探索卷积网络的线性性质来进行推理时加速"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>探索卷积网络的线性性质来进行推理时加速 | Ashun's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Ashun's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">我的学习记录</p>
      <img class="custom-logo-image" src="/uploads/a.png" alt="Ashun's Blog">
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/me" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">18</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">4</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">34</span></a></li><li class="menu-item menu-item-whisper"><a href="/whisper/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>whisper</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-number">1.</span> <span class="nav-text">基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mahalanobis-distance"><span class="nav-number">1.1.</span> <span class="nav-text">Mahalanobis distance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.2.</span> <span class="nav-text">度量学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dirac-distribution"><span class="nav-number">1.3.</span> <span class="nav-text">Dirac distribution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8C%83%E6%95%B0"><span class="nav-number">1.4.</span> <span class="nav-text">矩阵的范数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%A6%E5%8F%B7%E5%AE%9A%E4%B9%89"><span class="nav-number">2.1.</span> <span class="nav-text">符号定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%B0%E8%AE%A1%E5%BA%A6%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">估计度量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F"><span class="nav-number">2.2.1.</span> <span class="nav-text">马氏距离度量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%BA%A6%E9%87%8F"><span class="nav-number">2.2.2.</span> <span class="nav-text">数据协方差度量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%8E%E7%A7%A9%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E4%BC%B0%E8%AE%A1"><span class="nav-number">2.3.</span> <span class="nav-text">低秩矩阵分解估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%86%E8%A7%A3"><span class="nav-number">2.3.1.</span> <span class="nav-text">高维张量的分解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95%E8%89%B2%E5%8D%B7%E7%A7%AF%E4%BC%B0%E8%AE%A1"><span class="nav-number">2.3.2.</span> <span class="nav-text">单色卷积估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%8C%E8%89%B2%E5%8D%B7%E7%A7%AF%E4%BC%B0%E8%AE%A1"><span class="nav-number">2.3.3.</span> <span class="nav-text">双色卷积估计</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83"><span class="nav-number">2.4.</span> <span class="nav-text">微调</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="nav-number">3.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ashun"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">ashun</p>
  <div class="site-description" itemprop="description">个人博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ashun989" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ashun989" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ashun0606@gmail.com" title="E-Mail → mailto:ashun0606@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ashun989.github.io/2022/10/13/Linear-Structure-Within-Conv/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="ashun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ashun's Blog">
      <meta itemprop="description" content="个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="探索卷积网络的线性性质来进行推理时加速 | Ashun's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          探索卷积网络的线性性质来进行推理时加速
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-10-13 17:06:54" itemprop="dateCreated datePublished" datetime="2022-10-13T17:06:54+08:00">2022-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-02-12 20:24:32" itemprop="dateModified" datetime="2023-02-12T20:24:32+08:00">2023-02-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <img src="/2022/10/13/Linear-Structure-Within-Conv/image-20221017160950770.png" class="">
<p><strong>论文：</strong><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1404.0736.pdf">Exploiting Linear Structure
Within Convolutional Networks for Efficient Evaluation</a></p>
<p><strong>作者：</strong> <em>Emily Denton</em>, <em>Wojciech
Zaremba</em>, <em>Joan Bruna</em>, <em>Yann LeCun</em>, <em>Rob
Fergus</em></p>
<p><strong>录用情况：</strong>Neurips'2014</p>
<p><strong>第一作者单位：</strong>Dept. of Computer Science, Courant
Institute, New York University</p>
<blockquote>
<p>笔者最近在做一些用SVD分解卷积核的小实验，并且也在想该如何设计目标函数，让重参数化这件事变成可学习的？然后我发现早在14年就有人做了相关问题的研究；笔者看来，这篇文章的贡献为：</p>
<ul>
<li>给出了一种评估压缩后卷积核好坏的方式，并且通过在线学习的方式，修改了反向传播的梯度（不确定是不是这样）</li>
<li>归纳并尝试了对于高维张量的两种分解方法：SVD分解和外积分解；</li>
<li>结合聚类方法，针对浅层卷积和深层卷积的不同性质，设计了单色估计方法和双色估计方法；</li>
<li>给出一种微调方式：从最浅层开始，压缩一层，然后微调其上所有层，直至性能恢复，如此循环，看能最多压缩多少层；</li>
</ul>
<p>作者在实验部分用了比较老的模型，仅4层卷积和3层全连接层，现在来看非常简单，但是很适合做一个demo，然而作者原始的<a
href="">C++代码链接</a>已经失效了</p>
</blockquote>
<span id="more"></span>
<h2 id="基础知识">基础知识</h2>
<p>有关主成分分析和奇异值分解的知识在<a
href="https://ashun989.github.io/2022/08/10/linear-algebra/">线性代数要点总结</a>的最后部分有一些干货；</p>
<h3 id="mahalanobis-distance">Mahalanobis distance</h3>
<p>马氏距离用于衡量一个点<span
class="math inline">\(P\)</span>到一个分布<span
class="math inline">\(D\)</span>的距离，即<span
class="math inline">\(P\)</span>距离<span
class="math inline">\(D\)</span>的质心有多少标准差距离，因而也可以用于衡量两个分布的距离；马氏距离考虑到了数据集的相关性、并且具有尺度不变性，说人话就是，无论数据是否沿着各个轴分布，无论在各个维度上的尺度是否一致，如下图所示，马氏距离都能得到A相比于B，与分布的距离更远；</p>
<p><img src="v2-3cee35b79d272dda86e2604c160934ee_720w.jpeg" /></p>
只要将原始数据平移到以原点为中心，再旋转至主成分方向再除以各个方向的方差，之后再计算欧式距离，这就是马氏距离公式的由来，设数据为<span
class="math inline">\(X\in \mathbb R^{m\times n}\)</span>，其均值为<span
class="math inline">\(\mu_X\in \mathbb R^n\)</span>，其协方差矩阵为<span
class="math inline">\(\Sigma_X \in \mathbb R^{n\times
n}\)</span>，<strong>假设协方差矩阵是满秩的</strong>（即没有为0的特征值，又因为协方差矩阵半正定，意味着所有特征值为正），其特征值按照非增顺序依次为<span
class="math inline">\(\lambda_1, \lambda_2, \lambda_n\)</span>；<span
class="math inline">\(Y\)</span>是<span
class="math inline">\(X\)</span>平移至原点为中心后再旋转至主成分方向的形式，即<span
class="math inline">\(Y=U^TX\)</span>，其中<span
class="math inline">\(U\)</span>是单位正交矩阵，使得<span
class="math inline">\(\text{diag}\{\lambda_1,\cdots,\lambda_n\}=U^T\Sigma_XU\)</span>，对于数据点<span
class="math inline">\(x\)</span>，其到<span
class="math inline">\(X\)</span>的马氏距离的平方为： $$
<span class="math display">\[\begin{aligned}
D_M^2 &amp;= \frac{U^T(x_1-{\mu_X}_1)}{\lambda_1} + \cdots +
\frac{U^T(x_n-{\mu_X}_n)}{\lambda_n}\\
&amp;= (y_1, \cdots, y_n)\text{diag}\{\frac 1 {\lambda_1}, \cdots, \frac
1 {\lambda_n} \}
\left(
\begin{array}{c}
y_1\\
\vdots\\
y_n
\end{array}
\right)\\
&amp;= y^T(U^T\Sigma_XU)^{-1}y\\
&amp;= (x-\mu_X)^TUU^T\Sigma_X^{-1}UU^T(x-\mu_X)\\
&amp;= (x-\mu_X)^T\Sigma_X^{-1}(x-\mu_X)

\end{aligned}\]</span>
<p><span class="math display">\[
因此，点$x$到分布$X$的马氏距离为：
\]</span> D_M = <span class="math display">\[
如果$x$与$y$是两个服从同一分布且协方差矩阵为$\Sigma$的随机变量，则他们的距离为：
\]</span> D_M = $$
如果协方差矩阵是单位矩阵，则退化成欧式距离；如果协方差矩阵是对角矩阵，则退化成归一化的欧氏距离；</p>
<h3 id="度量学习">度量学习</h3>
<p>详见西瓜书第10章；</p>
<h3 id="dirac-distribution">Dirac distribution</h3>
<p>这种分布是理想电荷的分布：集中在一点。详见<a
target="_blank" rel="noopener" href="https://wuli.wiki/online/Delta.html">小时百科 - 狄拉克<span
class="math inline">\(\delta\)</span>函数</a>。笔者理解为，实现时即one-hot编码；</p>
<h3 id="矩阵的范数">矩阵的范数</h3>
<p><span class="math display">\[
||A||_p = (\sum_{i,j}|a_{i,j}|^p)^{1/p}
\]</span></p>
<p>其中，<span class="math inline">\(||A||_F=||A||_2\)</span></p>
<h2 id="方法">方法</h2>
<h3 id="符号定义">符号定义</h3>
<p><img src="image-20221017161636024.png" /></p>
<h3 id="估计度量">估计度量</h3>
<p>我们希望获得一个<span
class="math inline">\(\tilde{W}\)</span>，来估计网络中的<span
class="math inline">\(W\)</span>，能够在减少计算量的情况下保持性能；一个非常朴素的想法是最小化<span
class="math inline">\(||\tilde W -
W||_F\)</span>，但是，这假设了在模型权重张量上每个位置的参数都对预测做出均等的贡献，这是不合理的；作者提出了两种度量：</p>
<blockquote>
<p>这两种度量无非都是在给<span
class="math inline">\(W\)</span>加权，然后预测到这个加权的张量的一个近似常量，对于文中使用的SVD分解，这不是一个可迭代的算法（不能利用pytorch的自动微分偷懒了），因此直接把近似的目标设置为加权后的<span
class="math inline">\(W\)</span>，得到的结果再乘以权重的倒数即可；</p>
</blockquote>
<h4 id="马氏距离度量">马氏距离度量</h4>
<p>记<span class="math inline">\(\Theta = \{W_1, \cdots,
W_S\}\)</span>是<span
class="math inline">\(S\)</span>层网络的参数，<span
class="math inline">\(U(I;\Theta)\)</span>是网络对于输入图像<span
class="math inline">\(I\)</span>的softmax层的输出（各个类别的概率）；大小为<span
class="math inline">\(N\)</span>的训练集，训练对记为<span
class="math inline">\((I_n, y_n)\)</span>，记<span
class="math inline">\(U(I_n;\Theta)\)</span>中概率最高的而索引不等于真实标签<span
class="math inline">\(y_n\)</span>的<span
class="math inline">\(h\)</span>个索引组成序列<span
class="math inline">\(\{\beta_n\}\)</span>，那么对于第<span
class="math inline">\(s\)</span>层，在反向传播过程中为权重<span
class="math inline">\(W_s\)</span>计算一个（额外的）导数项： <span
class="math display">\[
d_{n,l,s}= \nabla_{W_s}(U(I_n;\Theta)-\delta(i-l)), n\le N, l\in
\{\beta_n\}, s\le S
\]</span> 其中，<span
class="math inline">\(\delta(i-l)\)</span>是以<span
class="math inline">\(l\)</span>为中心的狄拉克分布，应该就是在<span
class="math inline">\(l\)</span>为1其他位置为0的one-hot编码向量；</p>
<p>笔者认为，作者的意思是在一般的损失函数中添加了一个正则项（但只是在推理时计算梯度），目的是表示各层权重的各个位置对于避开那几个“最危险”的错误的能力；
<span class="math display">\[
\frac 1 2\sum_{n}^N\sum_{l\in \{\beta_n\}}
||U(I_n;\Theta)-\delta(i-l)||_2^2
\]</span> 有了这个正则项之后，作者再来计算<span
class="math inline">\(\tilde W\)</span>到<span
class="math inline">\(W\)</span>的马氏距离，将<span
class="math inline">\(\tilde W - W\)</span>可以展平成一个高维向量<span
class="math inline">\(w\in \mathbb R^P\)</span>，其导数<span
class="math inline">\(d\)</span>也可以展平成同样长度的向量，而对于<span
class="math inline">\(N\)</span>个样本在<span
class="math inline">\(h\)</span>个易错位置得到的正则化损失在<span
class="math inline">\(s\)</span>层的导数是一个基数为<span
class="math inline">\(N\times h\)</span>的导数向量的集合<span
class="math inline">\((d_{n,l,s})_{n,l}\)</span>，<span
class="math inline">\(\Sigma \in \mathbb R^{P\times
P}\)</span>是导数集合的协方差矩阵，精确的马氏距离为： <span
class="math display">\[
||\tilde W - W||^2_{maha} = w^T\Sigma^{-1}w
\]</span> 考虑到求<span
class="math inline">\(\Sigma^{-1}\)</span>的成本极高，因此作者进行了简化，即只使用<span
class="math inline">\(\Sigma\)</span>的对角线部分（<span
class="math inline">\(P\)</span>个维度的方差），因此，近似的马氏距离为：
<span class="math display">\[
||\tilde W-W||_\widetilde{maha} = \sum_p^P\alpha_pw_p, \ \ \text{where}
\ \ \alpha_p = \sqrt{\sum_{n,l}d_{n,l,s}(p)^2}
\]</span> 我们可以定义变量代换，<span class="math inline">\(\tilde
W&#39; - W’ = \alpha .* \tilde W - \alpha .* W\)</span>，则继续使用L2
norm，最小化<span class="math inline">\(||\tilde
W&#39;-W&#39;||_2\)</span>得到<span class="math inline">\(\tilde
W&#39;\)</span>，则<span class="math inline">\(\tilde W =
\alpha^{-1}.*\tilde W&#39;\)</span>；</p>
<h4 id="数据协方差度量">数据协方差度量</h4>
<p><img src="image-20221102223532182.png" /></p>
<h3 id="低秩矩阵分解估计">低秩矩阵分解估计</h3>
<h4 id="高维张量的分解">高维张量的分解</h4>
<p>对于张量<span class="math inline">\(W\in \mathbb R^{m\times n\times
k}\)</span>，首先将后两个维度合并成一个维度，使用SVD估计<span
class="math inline">\(\tilde W_m \in \mathbb R ^{m\times
(nk)}\)</span>，<span class="math inline">\(\tilde W_m \approx \tilde U
\tilde S \tilde V^T\)</span>；之后再对<span class="math inline">\(\tilde
V\in \mathbb R^{n\times
k}\)</span>使用SVD；记两次奇异值分解保留的秩分别为<span
class="math inline">\(K_1\)</span>，<span
class="math inline">\(K_2\)</span>;</p>
<p>另一种方法是使用矩阵的外积分解，最小化： <span
class="math display">\[
||W-\alpha\otimes\beta\otimes\gamma||_F
\]</span> 其中<span class="math inline">\(\alpha\in \mathbb
R^m\)</span>, <span class="math inline">\(\beta \in \mathbb
R^n\)</span>, <span class="math inline">\(\gamma \in \mathbb
R^k\)</span>；如果是对于秩为<span
class="math inline">\(K\)</span>的矩阵进行分解，只需要将<span
class="math inline">\(W\)</span>分解为多个外积之和；、</p>
<p>论文中给出了参考文献和实现细节，再次不再赘述；</p>
<h4 id="单色卷积估计">单色卷积估计</h4>
<p>对于某层卷积权重<span class="math inline">\(W\in \mathbb R^{C\times X
\times Y\times W}\)</span>，记第<span
class="math inline">\(w\)</span>个卷积核为<span
class="math inline">\(W_f \in \mathbb R^{C\times
(XY)}\)</span>；首先使秩为1的SVD，得到<span class="math inline">\(\tilde
W_f = \tilde U_f \tilde S_f \tilde
V_f^T\)</span>；之后为了进一步压缩，作者观察到，每个卷积核的<span
class="math inline">\(C\)</span>的通道也是比较冗余的，可以投影到<span
class="math inline">\(C&#39;\)</span>维的空间；对<span
class="math inline">\(\tilde U_f \in \mathbb R^{C\times
1}\)</span>使用聚类，得到<span
class="math inline">\(c_f\)</span>个聚类，因此<span
class="math inline">\(\tilde W_f = \tilde U_{c_f} \tilde S_f \tilde
V_f^T\)</span>其中<span class="math inline">\(\tilde
U_{c_f}\)</span>是原左奇异向量所在聚类的聚类中心；</p>
<h4 id="双色卷积估计">双色卷积估计</h4>
<p>除了卷积核各个通道间的冗余性，还有可能存在不同卷积核之间的冗余性。因此在双色方法中，作者首先对<span
class="math inline">\(W_C\in \mathbb R^{C\times
(XYF)}\)</span>进行聚类，得到<span
class="math inline">\(a\)</span>个类别，之后再对<span
class="math inline">\(W_F\in \mathbb R^{(CXY)\times
F}\)</span>进行聚类，得到<span
class="math inline">\(b\)</span>个类别，这样我们可以将<span
class="math inline">\(W\)</span>压缩为<span
class="math inline">\(a\times
b\)</span>个$W_SR^{C(XY)F}$3D张量，再使用先前的SVD分解或者外积分解即可；</p>
<blockquote>
<p>上述使用到的聚类，都是在每次迭代中平衡各个类别个数的（各个类数量相同），这两利于并行化</p>
</blockquote>
<h3 id="微调">微调</h3>
<p>相比于设计度量学习中的度量目标，作者还尝试了一种简单粗暴的方式，仅仅使用最简单的度量为目标进行逐层分解，之后冻结分解层及其先前的层，微调后面的层至性能恢复，然后再继续分解下一层；实验证明，这种方式，，要比手工设计的度量性能更好；</p>
<h2 id="参考链接">参考链接</h2>
<p><a
target="_blank" rel="noopener" href="https://www.cvmart.net/community/detail/3616">深入浅出的模型压缩：你一定从未见过如此通俗易懂的
Slimming 操作</a>，这里有一些有关模型压缩论文列表，有空可以看一看</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46626607">知乎 -
马氏距离</a></p>
<p><a target="_blank" rel="noopener" href="https://wuli.wiki/online/Delta.html">小时百科 - 狄拉克<span
class="math inline">\(\delta\)</span>函数</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Matrix_norm">wikipedia -
matrix norm</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/" rel="tag"><i class="fa fa-tag"></i> 模型压缩</a>
              <a href="/tags/%E5%8D%B7%E7%A7%AF%E5%88%86%E8%A7%A3/" rel="tag"><i class="fa fa-tag"></i> 卷积分解</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/05/ACNet/" rel="prev" title="ACNet论文阅读">
                  <i class="fa fa-chevron-left"></i> ACNet论文阅读
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/11/01/English/" rel="next" title="英语学习笔记（持续更新）">
                  英语学习笔记（持续更新） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ashun</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"ashun989","repo":"ashun989.github.io","client_id":"987971263864eebace39","client_secret":"57175a12b83a806d519086800d02bf809f59c14c","admin_user":"ashun989","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"eda829d792062e796f0a063fc8f3c0a0"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
