<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ashun989.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="article">
<meta property="og:title" content="Diffusion x 语义分割">
<meta property="og:url" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/index.html">
<meta property="og:site_name" content="Ashun&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DiffusionSeg/fig2.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DiffusionSeg/eq4.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DiffusionSeg/eq5.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DiffSeg/pipe.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/SegDiff/arch.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DMIISE/arch.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/Pix2Seq-D/arch.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/Pix2Seq-D/alg.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DDP/arch.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DenseDiffusion/observation.png">
<meta property="og:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DenseDiffusion/eq2.png">
<meta property="article:published_time" content="2023-03-30T12:30:43.000Z">
<meta property="article:modified_time" content="2023-09-09T07:37:25.242Z">
<meta property="article:author" content="ashun">
<meta property="article:tag" content="语义分割">
<meta property="article:tag" content="扩散模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/DiffusionSeg/fig2.png">


<link rel="canonical" href="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/","path":"2023/03/30/Diffuse-on-Seg/","title":"Diffusion x 语义分割"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Diffusion x 语义分割 | Ashun's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Ashun's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">我的学习记录</p>
      <img class="custom-logo-image" src="/uploads/a.png" alt="Ashun's Blog">
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/me" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">18</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">4</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">33</span></a></li><li class="menu-item menu-item-whisper"><a href="/whisper/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>whisper</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3zero-shotfew-shot"><span class="nav-number">1.</span> <span class="nav-text">无监督、Zero Shot、Few Shot</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#diffusionseg"><span class="nav-number">1.1.</span> <span class="nav-text">DiffusionSeg</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#diffumask"><span class="nav-number">1.2.</span> <span class="nav-text">DiffuMask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#diffseg"><span class="nav-number">1.3.</span> <span class="nav-text">DiffSeg</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E7%9B%91%E7%9D%A3"><span class="nav-number">2.</span> <span class="nav-text">全监督</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#segdiff"><span class="nav-number">2.1.</span> <span class="nav-text">SegDiff</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#diffusion-models-for-implicit-image-segmentation-ensembles"><span class="nav-number">2.2.</span> <span class="nav-text">Diffusion
Models for Implicit Image Segmentation Ensembles</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pix2seq-d"><span class="nav-number">2.3.</span> <span class="nav-text">Pix2Seq-D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ddp"><span class="nav-number">2.4.</span> <span class="nav-text">DDP</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96"><span class="nav-number">3.</span> <span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#geodiffusion"><span class="nav-number">3.1.</span> <span class="nav-text">GeoDiffusion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#densediffusion"><span class="nav-number">3.2.</span> <span class="nav-text">DenseDiffusion</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ashun"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">ashun</p>
  <div class="site-description" itemprop="description">个人博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ashun989" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ashun989" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ashun0606@gmail.com" title="E-Mail → mailto:ashun0606@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ashun989.github.io/2023/03/30/Diffuse-on-Seg/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="ashun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ashun's Blog">
      <meta itemprop="description" content="个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Diffusion x 语义分割 | Ashun's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Diffusion x 语义分割
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-30 20:30:43" itemprop="dateCreated datePublished" datetime="2023-03-30T20:30:43+08:00">2023-03-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-09 15:37:25" itemprop="dateModified" datetime="2023-09-09T15:37:25+08:00">2023-09-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>

</blockquote>
<span id="more"></span>
<h2 id="无监督zero-shotfew-shot">无监督、Zero Shot、Few Shot</h2>
<h3 id="diffusionseg">DiffusionSeg</h3>
<figure>
<img src="DiffusionSeg/fig2.png" alt="DiffusionSeg两阶段示意图" />
<figcaption aria-hidden="true">DiffusionSeg两阶段示意图</figcaption>
</figure>
<p>DiffusionSeg<a
href="#refer-anchor-ma2023diffusionseg"><sup>1</sup></a>提出了一种无监督语义分割/目标检测的两阶段算法。</p>
<p>Synthesis阶段： 1. 生成image：选择训练好的t2i Stable Diffusion<a
href="#refer-anchor-rombach2022high"><sup>2</sup></a>，从ImageNet中采样类别名称并且使用ChatGPT生成上下文丰富的prompt，与随机噪声送入模型进行inverse
diffusion，得到合成的输入图片； 2. 抽取、聚合mask：用prompt中cls
token抽取cross attention中的特征图 <span
class="math inline">\(A_c\)</span>（原始粗糙mask），并抽取self
attention的特征图 <span
class="math inline">\(A_s\)</span>，并且在不同层和不同时间步上聚合； 3.
Refine mask：根据“用<span class="math inline">\(A_s\)</span> refine
<span class="math inline">\(A_c\)</span> 的边界，用 <span
class="math inline">\(A_s\)</span> 和
输入图片像素间RGB距离和欧氏距离来提升coherence区域的响应”，设计了能量函数并且使用图割算法最小化；（比直接使用KMeans,NCut,
DenseCRF效果好）</p>
<p>Exploitation阶段：</p>
<ol type="1">
<li>DDPM的扩散过程每一步都需要引入随机噪声，这里使用DDIM的思路，获得确定的噪声，利于重建；之后在反向过程中，获得特征图；</li>
<li>输入图片和之前生成的prompt送入CLIP？</li>
<li>用AttentionCut生成的pseudo mask作为监督，训练简单的三层 FCN
Decoder（Diffusion Model 是冻结的）</li>
</ol>
<p>因为笔者知识储备不足，加之目前没有开放源代码，笔者还有如下疑问： 1.
为什么在DiffusionSeg中，类别标签要由CLIP选出，而不直接用AttentionCut中输入的类别标签？
2. objectness的能量函数的定义中，像素 <span
class="math inline">\(p\)</span> 属于前景/背景的先验从哪来？是使用阈值
<span class="math inline">\(\tau\)</span> 对 <span
class="math inline">\(A_c\)</span> 进行初步二值化得到的吗？以及，在
<span class="math inline">\(p \in \text{background}\)</span>
时的目标是不是少了一个负号？ <img src="DiffusionSeg/eq4.png" /> 3. Inner
Coherence中定义的Spacial Coherence <span
class="math inline">\(\mathcal{D}(p,q)\)</span> 是来自于哪个传统的方法？
<img src="DiffusionSeg/eq5.png" /></p>
<h3 id="diffumask">DiffuMask</h3>
<h3 id="diffseg">DiffSeg</h3>
<figure>
<img src="DiffSeg/pipe.png" alt="DiffSeg的流程图" />
<figcaption aria-hidden="true">DiffSeg的流程图</figcaption>
</figure>
<p>不同于DiffusionSeg和DiffuMask，使用cross attn
map获得文本指定的前景物体mask，DiffSeg<a
href="#tian2023diffuse"><sup>9</sup></a>只使用了self attn
map，获得物体分组信息。</p>
<p>本文观察总结了self attn的两大特点， 1. Intra-Attention
Similarity，即在一个像素 <span class="math inline">\((I,J)\)</span>
对应的2D注意力图 <span class="math inline">\(A(I,J,:,:)\)</span>
中，激活值高的区域往往是与 <span class="math inline">\((I,J)\)</span>
属于同一个 object group的； 2. Inter-Attention
Similarity，属于同一个object
group的两个像素对应的两个2D注意力图，应该是相似的；</p>
<p>低分辨率的注意力图在原始图像上有更大的感受野，因此激活区域比例往往更大一些。这样本文解释了为什么4个分辨率的attn
map都要使用。</p>
<p>整个后处理算法的步骤如下：</p>
<ul>
<li>首先，设置一组与分辨率成正比的超参，按照像素位置的对应关系，将多个分辨率的self
attn maps上采用、加权求和、归一化到 <span class="math inline">\(64\times
64\)</span> 个 <span class="math inline">\(64\times 64\)</span> self
attn maps。</li>
<li>在已知任意两张注意力图的距离的情况下，设计了一种迭代算法，从 <span
class="math inline">\(M^2\)</span> 个采样点对应的初始attn组集合 <span
class="math inline">\(\mathcal{L}_\alpha\)</span> 开始（ <span
class="math inline">\(M\le 64\)</span> ），在阈值 <span
class="math inline">\(\tau\)</span> 的过滤下，每次将候选attn组集合<span
class="math inline">\(\mathcal{L}_p\)</span> 中与其他attn距离小于 <span
class="math inline">\(\tau\)</span>
的聚合为新的attn；最终得到每个attn关注不同object/stuff的attn集合 <span
class="math inline">\(\mathcal{L}_p \in\mathbb{R}^{N_p\times 64 \times
64}\)</span>。距离度量使用forward KL和reverse KL的均值。</li>
<li>上采样到原图尺寸，并且逐像素位置上使用概率值最高的attn对应的label。</li>
</ul>
<blockquote>
<p>由于单张注意力图有和为1的性质，因此可以使用KL散度来衡量两张注意力图的相似性！</p>
</blockquote>
<h2 id="全监督">全监督</h2>
<p>尝试用逆扩散过程实现密集预测，输入图像的特征作为逆扩散过程中的“条件”。</p>
<h3 id="segdiff">SegDiff</h3>
<figure>
<img src="SegDiff/arch.png" alt="SegDiff框架图" />
<figcaption aria-hidden="true">SegDiff框架图</figcaption>
</figure>
<p>SegDiff<a
href="#amit2021segdiff"><sup>5</sup></a>修改了UNet的encoder，分别处理
<span class="math inline">\(x_t\)</span> 和图像 <span
class="math inline">\(I\)</span> 并将其融合。整个UNet可以表达为：</p>
<p><span class="math display">\[
\epsilon_\theta(x_t, I, t) = D(E(F(x_t) + G(I), t), t)
\]</span></p>
<p>其他与DDPM一致。</p>
<p>需要注意的是，SegDiff最终解决的问题是<strong>二值分割</strong>。对于Cityscapes这样的多目标数据集，采用交互式分割的设置（预先给定目标物体的bbox）。</p>
<h3
id="diffusion-models-for-implicit-image-segmentation-ensembles">Diffusion
Models for Implicit Image Segmentation Ensembles</h3>
<p>本文使用Diffusion Model解决二值脑瘤分割问题。</p>
<figure>
<img src="DMIISE/arch.png" alt="DMIISE流程图" />
<figcaption aria-hidden="true">DMIISE流程图</figcaption>
</figure>
<h3 id="pix2seq-d">Pix2Seq-D</h3>
<p>Pix2Seq-D<a href="#chen2022ageneralist"><sup>6</sup></a> 用Diffusion
Model解决全景分割问题。抛弃了UNet结构，单独设计了图像特征的encoder和mask
decoder。</p>
<p>在label的编码上使用了analog bits<a
href="#chen2022analog"><sup>7</sup></a>。</p>
<figure>
<img src="Pix2Seq-D/arch.png" alt="Pix2Seq-D模型框架" />
<figcaption aria-hidden="true">Pix2Seq-D模型框架</figcaption>
</figure>
<figure>
<img src="Pix2Seq-D/alg.png" alt="Pix2Seq-D训练和采样伪代码" />
<figcaption aria-hidden="true">Pix2Seq-D训练和采样伪代码</figcaption>
</figure>
<h3 id="ddp">DDP</h3>
<figure>
<img src="DDP/arch.png" alt="DDP的框架图" />
<figcaption aria-hidden="true">DDP的框架图</figcaption>
</figure>
<p>这篇文章（DDP<a
href="#ji2023ddp"><sup>3</sup></a>）在技术上的贡献包括：</p>
<ul>
<li>将噪声与图像特征拼接作为输入的、由几层attention堆叠的，map
decoder的简单设计；</li>
<li>通过探索多种方式，确定在加噪之前，使用可学习的参数将离散gt
label映射到连续空间；</li>
<li>确定了 cos schedule for <span
class="math inline">\(\alpha_t\)</span> 比 linear schedule for <span
class="math inline">\(\alpha_t\)</span> 要好；</li>
<li>为seg任务使用CE
loss，为depth任务使用sigloss，而不是用扩散模型原来用的L2损失，更好些；</li>
<li>观察到推理时过多的步数，性能下降，认为是训练和推理时噪声分布不一致造成的，通过在模型训练后期使用自训练解决了这个问题；</li>
</ul>
<p>在这样的pipeline下，模型还有两个故事性的贡献，均得益于不同时间步的推理得到不同的结果：</p>
<ul>
<li>动态推理能力</li>
<li>通过几个推理map的比较知道模型uncertainty的区域；</li>
</ul>
<p>与SegDiff的一个主要区别是，DDP没有使用参数量巨大的UNet；考虑到目标函数也换了，整个方法与Diffusion相关的就只有加噪、去噪的模式。</p>
<blockquote>
<p>DDP在pipeline上，损失函数的选择上，都与Pix2Seq-D很相似，在label的编码上也尝试过analog
bits，不过最终被可学西的编码替代。</p>
</blockquote>
<h2 id="其他">其他</h2>
<h3 id="geodiffusion">GeoDiffusion</h3>
<p>GeoDiffusion<a href="#chen2023intergrating"><sup>4</sup></a>
希望使用真实目标检测数据集训练一个能从layout生成图片（L2I）的生成模型，并用生成数据作为增强数据训练目标检测模型。</p>
<p>这篇文章在技术上的贡献包括：</p>
<ol type="1">
<li>探索了将stable diffusion模型finetune为GeoDiffusion的方法，细节包括：
<ul>
<li>将离散的bounding
box信息和相机角度信息通过索引可学习编码的方式转换为text embedding；</li>
<li>将前景区域按照其面积大小进行加权，面积越小，权重越高，损失权重越大；</li>
<li>训练时的超参设置；</li>
</ul></li>
<li>探索了3种评价生成数据的方式：
<ul>
<li>测试FID，并且使用在训练集上训练的Mask
R-CNN模型作为Oracle，在验证集上，用oracle对于生成数据进行预测并计算与gt
box的AP (类似YOLO
score)，与oracle在验证集上的AP越一致，说明数据越真实。</li>
<li>将生成数据与不同比例的真实数据混合，训练Faster
R-CNN模型，观察生成数据的增强效果；</li>
<li>对于训练集中出现的layout，使用随机flip和shift，发现生成结果也不错，这也被用在了detector的训练中；</li>
</ul></li>
<li>在COCO上训练的GeoDiffusion模型还具有不错的Inpainting能力。</li>
</ol>
<p>这篇文章提出的这种对于T2I
DMs的微调方式使得DMs在给定layout的情况下能够生成前景数量丰富的图片，但是这限制了微调后GeoDiffusion只能作为训练集的增强模型，其对于OOD的layout有一定泛化能力，但是对于训练集没有出现的类别以及不能再像原sd一样生成。</p>
<h3 id="densediffusion">DenseDiffusion</h3>
<p>DenseDiffusion<a
href="#kim2023dense"><sup>8</sup></a><strong>不微调stable
diffusion</strong>，通过一种调制注意力的方法，使得生成的图片与dense的文本匹配更好！</p>
<blockquote>
<p>在阅读Introduction和Related
work的时候，笔者发现自己关于Diffusion的论文看得太少了；</p>
</blockquote>
<figure>
<img src="DenseDiffusion/observation.png"
alt="对于sd的cross attn和self attn的定性观察（并不新鲜）" />
<figcaption aria-hidden="true">对于sd的cross attn和self
attn的定性观察（并不新鲜）</figcaption>
</figure>
<!-- ![对于sd的cross attn和self attn的定量观察](DenseDiffusion/observation2.png) -->
<p>作者先后用定性和定量分析说明attention map反映生成图像的layout。</p>
<p>无论cross attn，还是self attn，其注意力图调制的方式都可以表示为</p>
<p><img src="DenseDiffusion/eq2.png" /></p>
<p>其中 关系矩阵 <span class="math inline">\(R\)</span> 描述了key
value的“相似关系”（ <span class="math inline">\(R\)</span> 是binary map
），在cross attn和self attn中不同，<span
class="math inline">\(M_\text{pos}\)</span> 和 <span
class="math inline">\(M_\text{neg}\)</span> 用于调整attn value
range在调制前后相当。<span class="math inline">\(S\)</span>
表示每个query对应的段面积，旨在为不同大小的目标使用不同程度的调制，<span
class="math inline">\(\lambda_t\)</span> 是随着 <span
class="math inline">\(t\)</span>
从1到0逐渐变小的参数，因为在生成后期的调制会使得图退化。</p>
<p>其中每个矩阵的设计见原论文，或者<a
target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/b7_CqtaqKY2A_TxL86iosw">极市平台解读</a>。</p>
<blockquote>
<p>改动训练好的神经网络的参数往往导致性能锐减，但是在激活值上进行调制却可能有更好的效果。</p>
</blockquote>
<h2 id="参考文献">参考文献</h2>
<div id="refer-anchor-ma2023diffusionseg">

</div>
<ul>
<li>[1] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.09813">Ma, Chaofan, et al.
"DiffusionSeg: Adapting Diffusion Towards Unsupervised Object
Discovery." arXiv preprint arXiv:2303.09813 (2023).</a></li>
</ul>
<div id="refer-anchor-rombach2022high">

</div>
<ul>
<li>[2] <a
target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html">Rombach,
Robin, et al. "High-resolution image synthesis with latent diffusion
models." Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition. 2022.</a></li>
</ul>
<div id="ji2023ddp">

</div>
<ul>
<li>[3] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.17559.pdf">Ji, Yuanfeng, et
al. "Ddp: Diffusion model for dense visual prediction." arXiv preprint
arXiv:2303.17559 (2023).</a></li>
</ul>
<div id="chen2023intergrating">

</div>
<ul>
<li>[4] <a
target="_blank" rel="noopener" href="https://kaichen1998.github.io/projects/geodiffusion/">Chen, Kai,
et al. "Integrating Geometric Control into Text-to-Image Diffusion
Models for High-Quality Detection Data Generation via Text Prompt."
arXiv preprint arXiv:2306.04607 (2023).</a></li>
</ul>
<div id="amit2021segdiff">

</div>
<ul>
<li>[5] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.00390">Amit, Tomer, et al.
"Segdiff: Image segmentation with diffusion probabilistic models." arXiv
preprint arXiv:2112.00390 (2021).</a></li>
</ul>
<div id="chen2022ageneralist">

</div>
<ul>
<li>[6] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.06366">Chen, Ting, et al. "A
generalist framework for panoptic segmentation of images and videos."
arXiv preprint arXiv:2210.06366 (2022).</a></li>
</ul>
<div id="chen2022analog">

</div>
<ul>
<li>[7] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.06366">Chen, Ting, Ruixiang
Zhang, and Geoffrey Hinton. "Analog bits: Generating discrete data using
diffusion models with self-conditioning." arXiv preprint
arXiv:2208.04202 (2022).</a></li>
</ul>
<div id="kim2023dense">

</div>
<ul>
<li>[8] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.12964v1.pdf">Kim, Yunji, et
al. "Dense Text-to-Image Generation with Attention Modulation." arXiv
preprint arXiv:2308.12964 (2023).</a></li>
</ul>
<div id="tian2023diffuse">

</div>
<ul>
<li>[9] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.12469.pdf">Tian, Junjiao, et
al. "Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation
using Stable Diffusion." arXiv preprint arXiv:2308.12469
(2023).</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" rel="tag"><i class="fa fa-tag"></i> 语义分割</a>
              <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag"><i class="fa fa-tag"></i> 扩散模型</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/03/20/Contrast-Seg-Code/" rel="prev" title="ContrastiveSeg 代码阅读">
                  <i class="fa fa-chevron-left"></i> ContrastiveSeg 代码阅读
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/04/14/Mask-Classifier/" rel="next" title="语义分割，是像素分类问题还是mask分类问题？">
                  语义分割，是像素分类问题还是mask分类问题？ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ashun</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"ashun989","repo":"ashun989.github.io","client_id":"987971263864eebace39","client_secret":"57175a12b83a806d519086800d02bf809f59c14c","admin_user":"ashun989","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"33cc3ec28c51dfd2f3731c476a4ca42b"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
